---
title: Student AI Use Policy
parent: Course Policies
nav_order: 1
---

# Policy on Generative AI Use — Students

This course assumes you live in a world where generative AI exists and evolves fast. You may use it—but only if you're willing to use it well.

Let’s be clear: the **underpinning requirements of cognition have not changed**. Learning hasn’t changed. Literacy hasn’t changed. The burden on **discernment** has simply grown exponentially.

Your teacher uses AI tools with **high discernment**. Prompts are often 10x the length of the output. Wrestling a model into something meaningful takes *more* work, not less. That work sharpens judgment.

You are allowed to use chat assistants under these conditions:

- **Provide your full prompt, system instructions (if any), and raw output** alongside any assignment that involved an AI tool.
- **If you write by hand**, that’s better. You strengthen judgment and reduce later confusion.
- **Using AI to ask questions** while you're genuinely trying to learn? Good. Keep doing that.
- **Using AI to write work you turn in**? Different story. It wastes your teacher’s time and weakens your own judgment.

How will I know the difference?

Because I’ll ask you to:
- Present your thinking aloud
- Defend your ideas
- Solve problems with a pencil and your own brain

You got me, punk. Let’s build something real.

---
title: Family Guidance on AI Tools
parent: Introduction to Computer Science
nav_order: 2
---

# Policy on Generative AI Use — Families

Your student is in a course that meets the moment: one where AI is a real tool, not a forbidden trick.

We teach students to use these tools *with discernment*. The goal isn’t speed or automation. It’s deeper thinking, stronger judgment, and ownership of ideas.

Let’s be clear: **the foundational nature of learning and literacy has not changed**. Students still need to read, reason, write, and revise. What’s changed is the **burden on discernment**, which has increased exponentially in the presence of generative tools.

In practice, this means:
- Students may use generative AI tools, but must submit prompts and outputs alongside their work.
- Writing by hand is encouraged, especially during learning and assessment.
- Asking AI thoughtful questions during problem-solving is supported.
- Submitting AI-written work as their own is not.

The course is designed to detect shallow understanding. Students will regularly:
- Present and defend ideas aloud
- Complete pencil-and-paper assessments without tech assistance

We appreciate your support in reinforcing that these tools are powerful—but only when used responsibly.

---
title: Administrator Brief on AI Policy
parent: Introduction to Computer Science
nav_order: 3
---

# Policy on Generative AI Use — Administrator Brief

This course approaches AI as a reality, not a novelty. Students are taught to use generative tools *with high discernment*—not for shortcuts, but for thinking.

We operate from a foundational belief: **learning has not changed**. Cognitive demands, literacy, problem-solving, and reasoning remain central. What has changed is the **magnitude of discernment** required in evaluating and using tools that offer answers too quickly.

Key elements:
- AI use is permitted, but students must attach full prompts and raw outputs with submissions.
- Handwriting and analog thinking are built into instruction and assessment.
- Use of AI for idea development is encouraged; use for content substitution is not.

Assessment methods include:
- Frequent oral defenses and presentations
- In-class problem-solving without tech
- Cumulative judgment-building through writing and revision

This approach aligns with curriculum goals around reasoning, ownership, and ethical computing. It supports a culture of thinking, not outsourcing.

Happy to provide further detail or examples on request.

---
title: Course Statement on Mistakes
parent: Introduction to Computer Science
nav_order: 4
---

# Course Statement on Mistakes

You are expected to make mistakes in this course. Not because you’re careless, but because you’re thinking.

Mistakes are not failure. They are *evidence of cognition*. You don’t get to shortcut around them, and you don’t get to be ashamed of them. If you’re not making errors, you’re not pushing your brain into new territory—you’re just coasting.

We don’t celebrate mistakes for their own sake. We investigate them. We use them. You’ll be asked to reflect on them, trace their roots, and explain how you recovered from them. That is the actual work.

AI can’t do that part for you. It can generate plausible answers. It can’t generate your *understanding*. That comes from friction, revision, and judgment. Mistakes are your raw material.

Don’t hide them. Show your work. Defend your process. Learn.

Mistakes are the only honest thing you bring to the table at first. The rest you earn.
